syntax = "proto3";
package vision;

import "google/protobuf/empty.proto";

service Vision {
  // 1) Analyze Wingman images/metadata -> dict: ID-> confidence level
  rpc ProcessWingmanCamera (ProcessWingmanCameraRequest) returns (ProcessWingmanCameraReply) {}

  // 2) Analyze Fixation images/metadata -> dict: ID-> confidence level
  rpc ProcessFixationCamera (ProcessFixationCameraRequest) returns (ProcessFixationCameraReply) {}

  // 3) Fire-and-forget integer push (no return body)
  rpc OnBlockStart (OnBlockStartRequest) returns (google.protobuf.Empty) {}

  // 4) Fire-and-forget gaze frame (no return body)
  rpc GazeFrame(GazeFrameRequest) returns (google.protobuf.Empty);

  // 5) Fire-and-forget label target (no return body)
  rpc LabelTarget(LabelTargetRequest) returns (google.protobuf.Empty);
}




message ProcessWingmanCameraRequest {
  double  timestamp_ms     = 1;

  bytes  color_image      = 2;   // e.g., img colorData
  bytes  depth_image      = 3;   // e.g., img depthData

  // Extra context from your ZMQ payload
  string bbox_json        = 4;   // your bboxJson

}

message ProcessWingmanCameraReply {
  map<int32, float> id_scores = 1;
}




message ProcessFixationCameraRequest {
  double  timestamp_ms     = 1;

  bytes  color_image      = 2;   // e.g., img colorData
  bytes  depth_image      = 3;   // e.g., img depthData

  // Extra context from your ZMQ payload
  string bbox_json        = 4;   // your bboxJson

  bytes gaze_item_index_dtn = 5;
  bytes current_screen_location_bytes = 6;
}

message ProcessFixationCameraReply {
  map<int32, float> id_scores = 1;
}


message OnBlockStartRequest {
  string participant_id = 1;
  int32 study = 2;
  int32 block_idx = 3;  // this is the block index, in Unity this is called block id
  int32 block_marker = 4;  // this indicate the type of the block
  int32 difficulty = 5;
}

message GazeFrameRequest{
  map<int32, int32> id_gazed = 1;
}

message LabelTargetRequest {
  int32 idx = 1;
  int32 dtn = 2;
}
